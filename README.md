# Deep Reinforcement Learning homework

### Links
- [Course webpage](http://rail.eecs.berkeley.edu/deeprlcourse/)
- [My notes](https://docs.google.com/document/d/1HYiY45GziC97xGau0L5tOavSKBDPKqcZFYgpaz00ngI/edit?usp=sharing)
- [My course project](https://github.com/igormolybog/cs285-project)

### Content
- hw1: Imitation Learning (Behavioral clonning, DAgger)
- hw2: Poicy Gradient (reduced variance REINFORCE)
- hw3: Q-learning and Actor-critic (online vesrsions)
- hw4: Model-based methods 

### HW1
![DAgger](https://www.ocf.berkeley.edu/~igormolybog/GitHub/DAgger.png)
### HW2
![REINFORCE](https://www.ocf.berkeley.edu/~igormolybog/GitHub/REINFORCE.png)
### HW3

#### Actor-critic
![Actor-critic](https://www.ocf.berkeley.edu/~igormolybog/GitHub/actor-critic.png)

#### Q-learning
![Q-learning](https://www.ocf.berkeley.edu/~igormolybog/GitHub/q-learning.png)
Implemented both epsilon-greedy and Boltzmann exploration schemes

### HW4
![Model-based](https://www.ocf.berkeley.edu/~igormolybog/GitHub/model-based.png)
With random shooting
